# Example .env for Local Codebase Analyzer
# Copy to .env and edit values

# Local repo to analyze
LOCAL_PATH=/path/to/your/local/repo

# Optional: path to virtualenv (if provided)
VENV_PATH=/path/to/your/.venv

# External OpenAI-compatible endpoints (or leave blank to rely on env)
API_URL=https://api.regolo.ai/v1/

# API key to use with the external endpoints
API_KEY=sk-REPLACE_ME

# SQLite DB path
DATABASE_PATH=codebase.db

# Max file size (bytes) to index / embed
MAX_FILE_SIZE=200000

# Chunk processing settings
CHUNK_SIZE=800
CHUNK_OVERLAP=100

# DB writer workers (for background DB writer)
DB_WRITER_WORKERS=2

# Models: set the model names / identifiers your provider expects
# e.g. for embeddings: text-embedding-3-small or other provider model id
EMBEDDING_MODEL=text-embedding-3-small

# Model used for coding / generation (provider model id)
CODING_MODEL=gpt-4o-code-preview

# Uvicorn server configuration
# Host (default 127.0.0.1) and port (default 8000) used when launching uvicorn
UVICORN_HOST=127.0.0.1
UVICORN_PORT=8080

# FileWatcher configuration
# Enable/disable the background file watcher that monitors project changes (default: true)
FILE_WATCHER_ENABLED=true

# Interval in seconds between directory scans (default: 10, minimum: 5)
FILE_WATCHER_INTERVAL=10

# Debounce time in seconds before processing detected changes (default: 5, minimum: 1)
FILE_WATCHER_DEBOUNCE=5

# Debug configuration
# Enable debug mode to generate bash scripts with curl commands on timeout (default: false)
DEBUG=false
